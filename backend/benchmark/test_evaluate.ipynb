{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecea3f4e-7456-4bef-98e0-b07e38334d14",
   "metadata": {},
   "source": [
    "# Evaluate Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f68e2b-c4f2-43b8-a001-81a9273e6043",
   "metadata": {},
   "source": [
    "## Running Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b2eb5d9-a3b9-4a38-9a38-899d60ee01f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bf21871-e8fa-4834-b202-3421efd206d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODES = ['naive', 'local', 'global', 'hybrid']\n",
    "TEST_TYPES = ['compliant', 'sentence-noncompliant', 'half-noncompliant', 'total-noncompliant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b9e38e8d-f349-46be-ad78-2a0cef661144",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt = '''\n",
    "You are an expert in regulation compliance analysis. \n",
    "We have a system that tries to check the compliance of a regulation with a new proposed regulation. \n",
    "You have the regulation, the proposed regulation, and the difference between these too, the output \n",
    "of the system will be provided to you and you should check either if the output shows the compliance \n",
    "status of the proposed regulation with the regulation.\n",
    "If the regulation's compliance is checked with general rules or other regulations it is ok.\n",
    "If the changes made to the regulation are mentioned but it is said the regulation is compliant it is ok.\n",
    "If at least half of the non compliance reasons are given it is enough.\n",
    "\n",
    "regulation: \"{text}\"\n",
    "\n",
    "proposed_regulation: \"{test}\"\n",
    "\n",
    "compliance_status: \"{desc}\"\n",
    "\n",
    "system_output: \"{result}\"\n",
    "\n",
    "output should be in this format:\n",
    "if the system_output is correct: `True`\n",
    "if the system_output is not correct: `False - one line description why`\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05a8fbbc-3dec-495d-b3b9-3eb8f2018941",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=\"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\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10292bc7-d810-4a2e-b8ae-7685bdb04cf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"test_data_sample.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    samples = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bcef977-67f3-4d60-bb29-8eb5c0729601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gemini(prompt):\n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"google/gemini-2.5-pro-preview-06-05\",\n",
    "      messages=[\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": prompt\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2d12d0a1-dce1-47cf-93ef-41d8a13cf47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_results(sample, result, test_type):\n",
    "    text, test, result = sample['text'], sample[test_type], result[test_type]\n",
    "    test_desc = 'The proposed regulation is completely compliant with previous regulation'\n",
    "    if test_type != 'compliant':\n",
    "        test_desc = sample[f'{test_type}-desc']\n",
    "    prompt = evaluation_prompt.format(text=text, test=test, desc=test_desc, result=result)\n",
    "    return call_gemini(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a705c05f-b0e0-414e-8ff1-f13767fb0f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluations_for_mode(samples, results):\n",
    "    evaluations = []\n",
    "    true_dict = {\n",
    "        'compliant': 0,\n",
    "        'sentence-noncompliant': 0,\n",
    "        'half-noncompliant': 0,\n",
    "        'total-noncompliant': 0,\n",
    "    }\n",
    "    for i in range(len(results)):\n",
    "        sample, result = samples[i], results[i]\n",
    "        if sample['id'] != result['id']:\n",
    "            print(f'ids not matched for {i}')\n",
    "            continue\n",
    "        evaluation = {\n",
    "            'id': sample['id']\n",
    "        }\n",
    "        for test_type in TEST_TYPES:\n",
    "            test_eval = evaluate_results(sample, result, test_type)\n",
    "            evaluation[test_type] = test_eval\n",
    "            if test_eval == 'True':\n",
    "                true_dict[test_type] += 1\n",
    "        evaluations.append(evaluation)\n",
    "        print(f'Evaluation done for {i}')\n",
    "    return evaluations, true_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a3779890-6fee-49cb-a4bd-15ee07e1a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_percent = lambda d: {k: f\"{(v / 50) * 100:.2f}%\" for k, v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "86d44403-a54d-490b-8729-349b2ad6332f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done for 0\n",
      "Evaluation done for 1\n",
      "Evaluation done for 2\n",
      "Evaluation done for 3\n",
      "Evaluation done for 4\n",
      "Evaluation done for 5\n",
      "Evaluation done for 6\n",
      "Evaluation done for 7\n",
      "Evaluation done for 8\n",
      "Evaluation done for 9\n",
      "Evaluation done for 10\n",
      "Evaluation done for 11\n",
      "Evaluation done for 12\n",
      "Evaluation done for 13\n",
      "Evaluation done for 14\n",
      "Evaluation done for 15\n",
      "Evaluation done for 16\n",
      "Evaluation done for 17\n",
      "Evaluation done for 18\n",
      "Evaluation done for 19\n",
      "Evaluation done for 20\n",
      "Evaluation done for 21\n",
      "Evaluation done for 22\n",
      "Evaluation done for 23\n",
      "Evaluation done for 24\n",
      "Evaluation done for 25\n",
      "Evaluation done for 26\n",
      "Evaluation done for 27\n",
      "Evaluation done for 28\n",
      "Evaluation done for 29\n",
      "Evaluation done for 30\n",
      "Evaluation done for 31\n",
      "Evaluation done for 32\n",
      "Evaluation done for 33\n",
      "Evaluation done for 34\n",
      "Evaluation done for 35\n",
      "Evaluation done for 36\n",
      "Evaluation done for 37\n",
      "Evaluation done for 38\n",
      "Evaluation done for 39\n",
      "Evaluation done for 40\n",
      "Evaluation done for 41\n",
      "Evaluation done for 42\n",
      "Evaluation done for 43\n",
      "Evaluation done for 44\n",
      "Evaluation done for 45\n",
      "Evaluation done for 46\n",
      "Evaluation done for 47\n",
      "Evaluation done for 48\n",
      "Evaluation done for 49\n",
      "_________________________________________________________________________________________________________________________\n",
      "{'compliant': '78.00%', 'sentence-noncompliant': '14.00%', 'half-noncompliant': '22.00%', 'total-noncompliant': '46.00%'}\n",
      "_________________________________________________________________________________________________________________________\n",
      "Evaluation done for 0\n",
      "Evaluation done for 1\n",
      "Evaluation done for 2\n",
      "Evaluation done for 3\n",
      "Evaluation done for 4\n",
      "Evaluation done for 5\n",
      "Evaluation done for 6\n",
      "Evaluation done for 7\n",
      "Evaluation done for 8\n",
      "Evaluation done for 9\n",
      "Evaluation done for 10\n",
      "Evaluation done for 11\n",
      "Evaluation done for 12\n",
      "Evaluation done for 13\n",
      "Evaluation done for 14\n",
      "Evaluation done for 15\n",
      "Evaluation done for 16\n",
      "Evaluation done for 17\n",
      "Evaluation done for 18\n",
      "Evaluation done for 19\n",
      "Evaluation done for 20\n",
      "Evaluation done for 21\n",
      "Evaluation done for 22\n",
      "Evaluation done for 23\n",
      "Evaluation done for 24\n",
      "Evaluation done for 25\n",
      "Evaluation done for 26\n",
      "Evaluation done for 27\n",
      "Evaluation done for 28\n",
      "Evaluation done for 29\n",
      "Evaluation done for 30\n",
      "Evaluation done for 31\n",
      "Evaluation done for 32\n",
      "Evaluation done for 33\n",
      "Evaluation done for 34\n",
      "Evaluation done for 35\n",
      "Evaluation done for 36\n",
      "Evaluation done for 37\n",
      "Evaluation done for 38\n",
      "Evaluation done for 39\n",
      "Evaluation done for 40\n",
      "Evaluation done for 41\n",
      "Evaluation done for 42\n",
      "Evaluation done for 43\n",
      "Evaluation done for 44\n",
      "Evaluation done for 45\n",
      "Evaluation done for 46\n",
      "Evaluation done for 47\n",
      "Evaluation done for 48\n",
      "Evaluation done for 49\n",
      "_________________________________________________________________________________________________________________________\n",
      "{'compliant': '78.00%', 'sentence-noncompliant': '14.00%', 'half-noncompliant': '22.00%', 'total-noncompliant': '46.00%'}\n",
      "_________________________________________________________________________________________________________________________\n",
      "Evaluation done for 0\n",
      "Evaluation done for 1\n",
      "Evaluation done for 2\n",
      "Evaluation done for 3\n",
      "Evaluation done for 4\n",
      "Evaluation done for 5\n",
      "Evaluation done for 6\n",
      "Evaluation done for 7\n",
      "Evaluation done for 8\n",
      "Evaluation done for 9\n",
      "Evaluation done for 10\n",
      "Evaluation done for 11\n",
      "Evaluation done for 12\n",
      "Evaluation done for 13\n",
      "Evaluation done for 14\n",
      "Evaluation done for 15\n",
      "Evaluation done for 16\n",
      "Evaluation done for 17\n",
      "Evaluation done for 18\n",
      "Evaluation done for 19\n",
      "Evaluation done for 20\n",
      "Evaluation done for 21\n",
      "Evaluation done for 22\n",
      "Evaluation done for 23\n",
      "Evaluation done for 24\n",
      "Evaluation done for 25\n",
      "Evaluation done for 26\n",
      "Evaluation done for 27\n",
      "Evaluation done for 28\n",
      "Evaluation done for 29\n",
      "Evaluation done for 30\n",
      "Evaluation done for 31\n",
      "Evaluation done for 32\n",
      "Evaluation done for 33\n",
      "Evaluation done for 34\n",
      "Evaluation done for 35\n",
      "Evaluation done for 36\n",
      "Evaluation done for 37\n",
      "Evaluation done for 38\n",
      "Evaluation done for 39\n",
      "Evaluation done for 40\n",
      "Evaluation done for 41\n",
      "Evaluation done for 42\n",
      "Evaluation done for 43\n",
      "Evaluation done for 44\n",
      "Evaluation done for 45\n",
      "Evaluation done for 46\n",
      "Evaluation done for 47\n",
      "Evaluation done for 48\n",
      "Evaluation done for 49\n",
      "_________________________________________________________________________________________________________________________\n",
      "{'compliant': '78.00%', 'sentence-noncompliant': '14.00%', 'half-noncompliant': '22.00%', 'total-noncompliant': '46.00%'}\n",
      "_________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for mode in MODES:\n",
    "    with open(f\"test_data_results_{mode}.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        results = json.load(f)\n",
    "    evals, true_dict = run_evaluations_for_mode(samples, results)\n",
    "    print('_'*121)\n",
    "    print(format_percent(true_cnt))\n",
    "    print('_'*121)\n",
    "    with open(f\"test_data_evals_{mode}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(evaluations, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8116c08c-060b-423c-95ff-4d1a027a0582",
   "metadata": {},
   "source": [
    "## Evaluation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "080bca1f-6be3-4014-8ed0-f0bf9778f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_evals = {}\n",
    "for mode in MODES:\n",
    "    with open(f\"test_data_evals_{mode}.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        evals = json.load(f)\n",
    "    all_evals[mode] = evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b071d721-8897-474b-999c-f38e27c6f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_evals[MODES[0]])):\n",
    "    for test_type in TEST_TYPES:\n",
    "        tmp = all_evals[MODES[0]][i][test_type]\n",
    "        for mode in MODES:\n",
    "            if all_evals[mode][i][test_type] != tmp:\n",
    "                print(f'difference in {mode}, {i}, {test_type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315f063e-3e4e-48d0-9cd0-4df8ea9c156c",
   "metadata": {},
   "source": [
    "#### According to above the, results for all different modes of lightrag was the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a299f15c-f424-4be7-84c5-0962f38fed06",
   "metadata": {},
   "source": [
    "### Problems with compliant regulations analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94ca91f-7b1c-4863-99ba-1ac4e7f53452",
   "metadata": {},
   "source": [
    "- Incomplete detection of changes: The system frequently misses significant deletions and modifications, such as the omission of final lines referencing comparative tables.\n",
    "- Failure to identify non-compliance: It incorrectly asserts full compliance despite substantial alterations, like a change in domestic construction capability from 65% to 85%.\n",
    "- Missing critical omissions: The system overlooks crucial missing elements, including appendix references or specific budget sources and signing authorities.\n",
    "- Empty or incorrect output: The system sometimes produces no output or provides an entirely inaccurate assessment of compliance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f10b1a7-a009-4e27-88c4-829c458796a6",
   "metadata": {},
   "source": [
    "### Problems with sentence noncompliant regulations analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bb70c6-73bc-4960-8e07-0ec459e04658",
   "metadata": {},
   "source": [
    "- Inaccurate Compliance Assessment: The system frequently asserts full compliance despite clear contradictions, such as changing a tax rate from 1% to 8%.\n",
    "- Failure to Detect Critical Changes: It consistently misses significant alterations to core provisions, like a project changing from \"railway\" to \"freeway.\"\n",
    "- Omission of Key Non-Compliant Details: The system overlooks crucial discrepancies in financial figures, deadlines, or requirements, for instance, a change in allocated amount from 10 billion to 50 billion Rials.\n",
    "- Inability to Identify Fundamental Policy Reversals: It fails to recognize when the proposed regulation directly reverses the original intent, such as changing debt forgiveness from non-approval to approval.\n",
    "- Lack of Contextual Understanding: The system analyzes proposed regulations in isolation, rather than comparing them against original regulations to identify non-compliance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44507b61-e6c2-4dea-9e14-acac0a85f325",
   "metadata": {},
   "source": [
    "### Problems with half noncompliant regulations analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7958c2-877d-4213-8a6a-9dd161d07228",
   "metadata": {},
   "source": [
    "- Failure to compare with base regulation: The system consistently misses non-compliance by not comparing the proposed text to the original, e.g., missing changes in legal basis or validity period.\n",
    "- Incorrectly claiming full compliance: It frequently states compliance even when fundamental contradictions exist, such as changing a tax rate from zero to 20%.\n",
    "- Missing multiple non-compliance points: The system fails to identify several critical discrepancies simultaneously, like differences in amount, priority of issuance, and coordination for issuance time.\n",
    "- Analyzing regulations in isolation: It assesses proposed regulations without considering their original context, e.g., failing to identify that domestic content changes violate the original regulation.\n",
    "- Misunderstanding core regulatory intent: The system can completely misinterpret a regulation's purpose, such as stating price increases are allowed when explicitly forbidden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5dcf13-6b1d-40a1-a52b-afc35af56d15",
   "metadata": {},
   "source": [
    "### Problems with total noncompliant regulations analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad1b8d8-9a99-4d1a-8a52-8741fb2c9a8b",
   "metadata": {},
   "source": [
    "- Failure to compare regulations: The system consistently neglects to compare proposed regulations with original ones, leading to missed contradictions (e.g., analyzing a tax change on basic goods in isolation instead of comparing it to a tax increase on luxury goods).\n",
    "- Incorrectly asserting full compliance: It frequently claims compliance even when the proposed regulation fundamentally contradicts or reverses the original (e.g., stating compliance when an \"approval to sell\" is changed to a \"disapproval to sell\").\n",
    "- Treating proposed regulation as current law: The system often assumes the proposed regulation is already valid and checks its compliance against general laws, ignoring direct conflicts with the original (e.g., confirming non-compliant content of the proposed regulation instead of its non-compliance with the original).\n",
    "- Missing complete contradictions/reversals: It fails to identify instances where the proposed regulation is the exact opposite of the original in all key aspects (e.g., completely reversing a decision to extend a deadline to mandating immediate implementation and fines).\n",
    "- Misinterpreting original intent: The system can fundamentally misunderstand the original regulation's purpose, leading to incorrect compliance assessments (e.g., stating original regulation eliminated subsidies when it established them)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c28a30-a7cd-4720-8b8d-1aae99765db1",
   "metadata": {},
   "source": [
    "### Problems Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422c824d-8055-48f7-a174-525299b76d8a",
   "metadata": {},
   "source": [
    "- Inadequate Comparison: The system consistently fails to compare proposed regulations with original ones, missing contradictions and fundamental changes.\n",
    "- False Compliance Claims: It frequently asserts full compliance even when proposed regulations contradict or reverse original intent.\n",
    "- Contextual Blindness: The system often analyzes proposed regulations in isolation, treating them as current law and ignoring their relationship with original versions.\n",
    "- Missed Reversals & Contradictions: It fails to identify complete reversals, fundamental policy shifts, or direct contradictions between proposed and original regulations.\n",
    "- Misinterpretation of Intent: The system frequently misunderstands the core purpose or intent of original regulations, leading to inaccurate assessments.\n",
    "- Overlooked Critical Changes: It consistently misses significant alterations, deletions, omissions, or discrepancies in key provisions, details, or financial figures.\n",
    "- Incomplete Non-Compliance Detection: The system often fails to identify multiple points of non-compliance simultaneously.\n",
    "- Erroneous or Absent Output: The system can produce no output or provide entirely inaccurate compliance assessments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff268b2-b1d8-48e4-bed5-2365270a8f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
